{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Донавчання детектора об'єктів на датасеті ArTaxOr\n",
        "\n",
        "Цей notebook містить повний пайплайн для донавчання моделі YOLOv8 на датасеті [ArTaxOr (Arthropod Taxonomy Orders Object Detection Dataset)](https://www.kaggle.com/datasets/mistag/arthropod-taxonomy-orders-object-detection-dataset) з Kaggle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Встановлення залежностей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Встановлення необхідних бібліотек\n",
        "%pip install ultralytics>=8.0.0 -q\n",
        "%pip install opencv-python>=4.8.0 -q\n",
        "%pip install pillow>=10.0.0 -q\n",
        "%pip install pyyaml>=6.0 -q\n",
        "%pip install tqdm>=4.65.0 -q\n",
        "%pip install kagglehub -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Імпорт бібліотек\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import kagglehub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Завантаження датасету з Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Налаштування шляхів\n",
        "OUTPUT_DIR = \"/kaggle/working\"\n",
        "DATASET_DIR = os.path.join(OUTPUT_DIR, \"dataset\")\n",
        "YOLO_DATASET_DIR = os.path.join(OUTPUT_DIR, \"yolo_dataset\")\n",
        "\n",
        "print(f\"Робоча директорія: {OUTPUT_DIR}\")\n",
        "\n",
        "# Завантаження датасету через kagglehub\n",
        "print(\"\\nЗавантаження датасету через kagglehub..\")\n",
        "print(\"Це може зайняти деякий час при першому запуску...\")\n",
        "\n",
        "try:\n",
        "    # Завантажуємо датасет через kagglehub\n",
        "    dataset_path = kagglehub.dataset_download(\"mistag/arthropod-taxonomy-orders-object-detection-dataset\")\n",
        "    print(f\"\\nДатасет завантажено в: {dataset_path}\")\n",
        "    \n",
        "    # Копіюємо датасет у робочу директорію для зручності\n",
        "    if os.path.exists(dataset_path):\n",
        "        # Шукаємо директорію ArTaxOr або використовуємо корінь датасету\n",
        "        potential_artaxor = os.path.join(dataset_path, \"ArTaxOr\")\n",
        "        if os.path.exists(potential_artaxor):\n",
        "            DATASET_DIR = potential_artaxor\n",
        "        else:\n",
        "            # Шукаємо рекурсивно директорію з XML або JSON файлами\n",
        "            for root, dirs, files in os.walk(dataset_path):\n",
        "                xml_files = [f for f in files if f.endswith('.xml')]\n",
        "                json_files = [f for f in files if f.endswith('.json')]\n",
        "                if xml_files or json_files:\n",
        "                    DATASET_DIR = root\n",
        "                    break\n",
        "            # Якщо не знайшли, використовуємо корінь\n",
        "            if DATASET_DIR == os.path.join(OUTPUT_DIR, \"dataset\"):\n",
        "                DATASET_DIR = dataset_path\n",
        "        \n",
        "        print(f\"Використовується директорія датасету: {DATASET_DIR}\")\n",
        "        \n",
        "        # Показуємо структуру датасету (перші 3 рівні)\n",
        "        print(\"\\nСтруктура датасету:\")\n",
        "        for root, dirs, files in os.walk(DATASET_DIR):\n",
        "            level = root.replace(DATASET_DIR, '').count(os.sep)\n",
        "            if level > 2:  # Обмежуємо глибину для читабельності\n",
        "                continue\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            # Показуємо файли анотацій\n",
        "            annotation_files = [f for f in files if f.endswith(('.xml', '.json'))]\n",
        "            if annotation_files:\n",
        "                for file in annotation_files[:3]:\n",
        "                    print(f\"{subindent}{file}\")\n",
        "                if len(annotation_files) > 3:\n",
        "                    print(f\"{subindent}... та ще {len(annotation_files) - 3} файлів анотацій\")\n",
        "            # Показуємо зображення\n",
        "            image_files = [f for f in files if f.endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "            if image_files and not annotation_files:\n",
        "                for file in image_files[:3]:\n",
        "                    print(f\"{subindent}{file}\")\n",
        "                if len(image_files) > 3:\n",
        "                    print(f\"{subindent}... та ще {len(image_files) - 3} зображень\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nПОМИЛКА при завантаженні датасету: {e}\")\n",
        "    print(\"\\nСпробуйте альтернативний спосіб:\")\n",
        "    print(\"1. Додайте датасет через Add Data -> Search Datasets\")\n",
        "    print(\"2. Або переконайтеся, що у вас є доступ до датасету\")\n",
        "    DATASET_DIR = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Функції для конвертації датасету у формат YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_pascal_voc(xml_path):\n",
        "    \"\"\"\n",
        "    Парсить XML файл у форматі Pascal VOC\n",
        "    Повертає список bbox у форматі [class_id, x_center, y_center, width, height] (нормалізовані)\n",
        "    \"\"\"\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    # Отримуємо розміри зображення\n",
        "    size = root.find('size')\n",
        "    img_width = int(size.find('width').text)\n",
        "    img_height = int(size.find('height').text)\n",
        "    \n",
        "    boxes = []\n",
        "    for obj in root.findall('object'):\n",
        "        # Отримуємо клас (може бути name або class)\n",
        "        class_name = obj.find('name').text\n",
        "        \n",
        "        # Отримуємо bbox\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "        \n",
        "        # Конвертуємо в YOLO формат (нормалізовані координати центру та розміри)\n",
        "        x_center = ((xmin + xmax) / 2) / img_width\n",
        "        y_center = ((ymin + ymax) / 2) / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "        \n",
        "        boxes.append({\n",
        "            'class': class_name,\n",
        "            'bbox': [x_center, y_center, width, height]\n",
        "        })\n",
        "    \n",
        "    return boxes, img_width, img_height\n",
        "\n",
        "def parse_azure_custom_vision(json_path, img_path=None, img_width=None, img_height=None):\n",
        "    \"\"\"\n",
        "    Парсить JSON файл у форматі Azure Custom Vision або VoTT\n",
        "    Повертає список bbox у форматі [class_id, x_center, y_center, width, height] (нормалізовані)\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    boxes = []\n",
        "    \n",
        "    # Отримуємо розміри зображення\n",
        "    if img_width is None or img_height is None:\n",
        "        if 'asset' in data:\n",
        "            # Azure Custom Vision формат\n",
        "            asset = data.get('asset', {})\n",
        "            img_width = asset.get('width')\n",
        "            img_height = asset.get('height')\n",
        "        elif 'image' in data:\n",
        "            # Альтернативний формат\n",
        "            image_info = data.get('image', {})\n",
        "            img_width = image_info.get('width')\n",
        "            img_height = image_info.get('height')\n",
        "    \n",
        "    # Якщо розміри не знайдені в JSON, спробуємо завантажити зображення\n",
        "    if (img_width is None or img_height is None) and img_path is not None:\n",
        "        try:\n",
        "            from PIL import Image\n",
        "            with Image.open(img_path) as img:\n",
        "                img_width, img_height = img.size\n",
        "        except Exception as e:\n",
        "            print(f\"Попередження: не вдалося отримати розміри зображення {img_path}: {e}\")\n",
        "            return boxes, None, None\n",
        "    \n",
        "    if img_width is None or img_height is None:\n",
        "        return boxes, None, None\n",
        "    \n",
        "    # Обробляємо регіони/анотації\n",
        "    regions = []\n",
        "    if 'regions' in data:\n",
        "        regions = data['regions']\n",
        "    elif 'annotations' in data:\n",
        "        regions = data['annotations']\n",
        "    elif 'objects' in data:\n",
        "        regions = data['objects']\n",
        "    \n",
        "    for region in regions:\n",
        "        # Отримуємо клас\n",
        "        class_name = None\n",
        "        if 'tags' in region and len(region['tags']) > 0:\n",
        "            class_name = region['tags'][0]  # Беремо перший тег\n",
        "        elif 'label' in region:\n",
        "            class_name = region['label']\n",
        "        elif 'name' in region:\n",
        "            class_name = region['name']\n",
        "        elif 'class' in region:\n",
        "            class_name = region['class']\n",
        "        \n",
        "        if class_name is None:\n",
        "            continue\n",
        "        \n",
        "        # Отримуємо bbox\n",
        "        x_center = None\n",
        "        y_center = None\n",
        "        norm_width = None\n",
        "        norm_height = None\n",
        "        \n",
        "        if 'boundingBox' in region:\n",
        "            # Azure Custom Vision формат: {left, top, width, height}\n",
        "            bbox_info = region['boundingBox']\n",
        "            left = float(bbox_info.get('left', 0))\n",
        "            top = float(bbox_info.get('top', 0))\n",
        "            width = float(bbox_info.get('width', 0))\n",
        "            height = float(bbox_info.get('height', 0))\n",
        "            \n",
        "            # Конвертуємо в YOLO формат\n",
        "            x_center = (left + width / 2) / img_width\n",
        "            y_center = (top + height / 2) / img_height\n",
        "            norm_width = width / img_width\n",
        "            norm_height = height / img_height\n",
        "        elif 'bbox' in region:\n",
        "            # Альтернативний формат: [x_min, y_min, width, height] або [x_min, y_min, x_max, y_max]\n",
        "            bbox_coords = region['bbox']\n",
        "            if len(bbox_coords) == 4:\n",
        "                if bbox_coords[2] < 1 and bbox_coords[3] < 1:\n",
        "                    # Вже нормалізовані координати\n",
        "                    x_center, y_center, norm_width, norm_height = bbox_coords\n",
        "                else:\n",
        "                    # Абсолютні координати\n",
        "                    x_min, y_min, x_max, y_max = bbox_coords\n",
        "                    x_center = ((x_min + x_max) / 2) / img_width\n",
        "                    y_center = ((y_min + y_max) / 2) / img_height\n",
        "                    norm_width = (x_max - x_min) / img_width\n",
        "                    norm_height = (y_max - y_min) / img_height\n",
        "        elif 'points' in region:\n",
        "            # Формат з точками\n",
        "            points = region['points']\n",
        "            if len(points) >= 2:\n",
        "                x_coords = [p.get('x', p[0] if isinstance(p, (list, tuple)) else 0) for p in points]\n",
        "                y_coords = [p.get('y', p[1] if isinstance(p, (list, tuple)) else 0) for p in points]\n",
        "                x_min, x_max = min(x_coords), max(x_coords)\n",
        "                y_min, y_max = min(y_coords), max(y_coords)\n",
        "                x_center = ((x_min + x_max) / 2) / img_width\n",
        "                y_center = ((y_min + y_max) / 2) / img_height\n",
        "                norm_width = (x_max - x_min) / img_width\n",
        "                norm_height = (y_max - y_min) / img_height\n",
        "        \n",
        "        if x_center is not None and y_center is not None:\n",
        "            boxes.append({\n",
        "                'class': class_name,\n",
        "                'bbox': [x_center, y_center, norm_width, norm_height]\n",
        "            })\n",
        "    \n",
        "    return boxes, img_width, img_height\n",
        "\n",
        "def parse_coco(json_path):\n",
        "    \"\"\"\n",
        "    Парсить JSON файл у форматі COCO\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Створюємо мапи для швидкого пошуку\n",
        "    images = {img['id']: img for img in data['images']}\n",
        "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    \n",
        "    # Групуємо анотації по зображенням\n",
        "    annotations_by_image = {}\n",
        "    for ann in data['annotations']:\n",
        "        image_id = ann['image_id']\n",
        "        if image_id not in annotations_by_image:\n",
        "            annotations_by_image[image_id] = []\n",
        "        annotations_by_image[image_id].append(ann)\n",
        "    \n",
        "    return images, categories, annotations_by_image\n",
        "\n",
        "def convert_coco_to_yolo(images, categories, annotations_by_image, class_mapping):\n",
        "    \"\"\"\n",
        "    Конвертує анотації COCO у формат YOLO\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for image_id, image_info in images.items():\n",
        "        img_width = image_info['width']\n",
        "        img_height = image_info['height']\n",
        "        file_name = image_info['file_name']\n",
        "        \n",
        "        boxes = []\n",
        "        if image_id in annotations_by_image:\n",
        "            for ann in annotations_by_image[image_id]:\n",
        "                category_id = ann['category_id']\n",
        "                class_name = categories[category_id]\n",
        "                \n",
        "                if class_name not in class_mapping:\n",
        "                    continue\n",
        "                \n",
        "                class_id = class_mapping[class_name]\n",
        "                \n",
        "                # COCO bbox формат: [x_min, y_min, width, height]\n",
        "                x_min, y_min, width, height = ann['bbox']\n",
        "                \n",
        "                # Конвертуємо в YOLO формат\n",
        "                x_center = (x_min + width / 2) / img_width\n",
        "                y_center = (y_min + height / 2) / img_height\n",
        "                norm_width = width / img_width\n",
        "                norm_height = height / img_height\n",
        "                \n",
        "                boxes.append({\n",
        "                    'class_id': class_id,\n",
        "                    'bbox': [x_center, y_center, norm_width, norm_height]\n",
        "                })\n",
        "        \n",
        "        result[file_name] = boxes\n",
        "    \n",
        "    return result\n",
        "\n",
        "def detect_format(dataset_path):\n",
        "    \"\"\"\n",
        "    Визначає формат анотацій датасету\n",
        "    \"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    \n",
        "    if not dataset_path.exists():\n",
        "        print(f\"ПОМИЛКА: Директорія не існує: {dataset_path}\")\n",
        "        return None, None\n",
        "    \n",
        "    print(f\"\\nПошук анотацій в: {dataset_path}\")\n",
        "    \n",
        "    # Перевірка на Pascal VOC (XML файли)\n",
        "    xml_files = list(dataset_path.rglob(\"*.xml\"))\n",
        "    if xml_files:\n",
        "        print(f\"Знайдено {len(xml_files)} XML файлів (Pascal VOC формат)\")\n",
        "        print(f\"Приклад файлів:\")\n",
        "        for xml_file in xml_files[:3]:\n",
        "            print(f\"  - {xml_file}\")\n",
        "        if len(xml_files) > 3:\n",
        "            print(f\"  ... та ще {len(xml_files) - 3} файлів\")\n",
        "        return \"pascal_voc\", xml_files\n",
        "    \n",
        "    # Перевірка на JSON файли\n",
        "    json_files = list(dataset_path.rglob(\"*.json\"))\n",
        "    if json_files:\n",
        "        print(f\"Знайдено {len(json_files)} JSON файлів\")\n",
        "        \n",
        "        # Спочатку перевіряємо, чи є JSON файли в папках annotations\n",
        "        annotation_json_files = []\n",
        "        for json_file in json_files:\n",
        "            if 'annotations' in str(json_file) or json_file.parent.name == 'annotations':\n",
        "                annotation_json_files.append(json_file)\n",
        "        \n",
        "        # Якщо знайшли JSON файли в annotations папках, перевіряємо їх формат\n",
        "        if annotation_json_files:\n",
        "            print(f\"Знайдено {len(annotation_json_files)} JSON файлів в папках annotations\")\n",
        "            # Перевіряємо структуру перших кількох файлів\n",
        "            azure_format_count = 0\n",
        "            coco_format_count = 0\n",
        "            \n",
        "            for json_file in annotation_json_files[:5]:  # Перевіряємо перші 5 файлів\n",
        "                try:\n",
        "                    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                        data = json.load(f)\n",
        "                        \n",
        "                        # Перевіряємо структуру COCO\n",
        "                        has_images = 'images' in data\n",
        "                        has_annotations = 'annotations' in data\n",
        "                        has_categories = 'categories' in data\n",
        "                        \n",
        "                        if has_images and has_annotations and has_categories:\n",
        "                            coco_format_count += 1\n",
        "                            continue\n",
        "                        \n",
        "                        # Перевіряємо структуру Azure Custom Vision/VoTT\n",
        "                        has_asset = 'asset' in data\n",
        "                        has_regions = 'regions' in data\n",
        "                        has_annotations_alt = 'annotations' in data and not has_images  # annotations без images = не COCO\n",
        "                        has_objects = 'objects' in data\n",
        "                        \n",
        "                        # Azure Custom Vision має asset + regions, або regions, або annotations (як список об'єктів)\n",
        "                        if (has_asset and has_regions) or (has_regions) or (has_annotations_alt and isinstance(data.get('annotations'), list)):\n",
        "                            azure_format_count += 1\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "            \n",
        "            # Визначаємо формат на основі перевірки\n",
        "            if azure_format_count > 0 and coco_format_count == 0:\n",
        "                print(f\"Виявлено Azure Custom Vision/VoTT формат ({azure_format_count} з {min(5, len(annotation_json_files))} перевірених файлів)\")\n",
        "                return \"azure_custom_vision\", annotation_json_files\n",
        "            elif coco_format_count > 0:\n",
        "                # Шукаємо головний COCO файл (не в annotations)\n",
        "                for json_file in json_files:\n",
        "                    if 'annotations' not in str(json_file) or json_file.parent.name != 'annotations':\n",
        "                        try:\n",
        "                            with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                                data = json.load(f)\n",
        "                                if 'images' in data and 'annotations' in data and 'categories' in data:\n",
        "                                    print(f\"Знайдено COCO формат в: {json_file}\")\n",
        "                                    return \"coco\", json_file\n",
        "                        except:\n",
        "                            continue\n",
        "        \n",
        "        # Якщо не знайшли в annotations, перевіряємо всі JSON файли на COCO\n",
        "        for json_file in json_files[:20]:  # Перевіряємо більше файлів\n",
        "            try:\n",
        "                with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "                    # Перевіряємо структуру COCO\n",
        "                    has_images = 'images' in data\n",
        "                    has_annotations = 'annotations' in data\n",
        "                    has_categories = 'categories' in data\n",
        "                    \n",
        "                    if has_images and has_annotations and has_categories:\n",
        "                        print(f\"Знайдено COCO формат в: {json_file}\")\n",
        "                        return \"coco\", json_file\n",
        "            except json.JSONDecodeError as e:\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    # Діагностика: показуємо що знайдено\n",
        "    print(\"\\nДіагностика:\")\n",
        "    print(f\"Перевірено директорію: {dataset_path}\")\n",
        "    \n",
        "    # Показуємо всі файли в директорії\n",
        "    all_files = list(dataset_path.rglob(\"*\"))\n",
        "    files_by_ext = {}\n",
        "    for file in all_files:\n",
        "        if file.is_file():\n",
        "            ext = file.suffix.lower()\n",
        "            if ext not in files_by_ext:\n",
        "                files_by_ext[ext] = []\n",
        "            files_by_ext[ext].append(file)\n",
        "    \n",
        "    print(f\"\\nЗнайдені файли за розширенням:\")\n",
        "    for ext, files in sorted(files_by_ext.items()):\n",
        "        print(f\"  {ext}: {len(files)} файлів\")\n",
        "        if len(files) <= 5:\n",
        "            for f in files:\n",
        "                print(f\"    - {f}\")\n",
        "        else:\n",
        "            for f in files[:3]:\n",
        "                print(f\"    - {f}\")\n",
        "            print(f\"    ... та ще {len(files) - 3} файлів\")\n",
        "    \n",
        "    # Перевіряємо чи є піддиректорії\n",
        "    subdirs = [d for d in dataset_path.iterdir() if d.is_dir()]\n",
        "    if subdirs:\n",
        "        print(f\"\\nПіддиректорії:\")\n",
        "        for subdir in subdirs[:10]:\n",
        "            print(f\"  - {subdir.name}/\")\n",
        "        if len(subdirs) > 10:\n",
        "            print(f\"  ... та ще {len(subdirs) - 10} директорій\")\n",
        "    \n",
        "    return None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_dataset(input_path, output_path, train_split=0.8, val_split=0.1):\n",
        "    \"\"\"\n",
        "    Конвертує датасет у формат YOLO\n",
        "    \n",
        "    Args:\n",
        "        input_path: Шлях до вхідного датасету\n",
        "        output_path: Шлях для вихідного датасету YOLO\n",
        "        train_split: Частка даних для навчання\n",
        "        val_split: Частка даних для валідації\n",
        "    \"\"\"\n",
        "    input_path = Path(input_path)\n",
        "    output_path = Path(output_path)\n",
        "    \n",
        "    # Створюємо структуру директорій YOLO\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        (output_path / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "        (output_path / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Перевіряємо чи існує вхідна директорія\n",
        "    if not input_path.exists():\n",
        "        print(f\"ПОМИЛКА: Вхідна директорія не існує: {input_path}\")\n",
        "        print(\"Переконайтеся, що датасет завантажено правильно\")\n",
        "        return\n",
        "    \n",
        "    # Визначаємо формат датасету\n",
        "    format_type, format_data = detect_format(input_path)\n",
        "    \n",
        "    if format_type is None:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ПОМИЛКА: не вдалося визначити формат анотацій\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"Підтримувані формати:\")\n",
        "        print(\"  - Pascal VOC: XML файли з анотаціями\")\n",
        "        print(\"  - COCO: JSON файли зі структурою {images, annotations, categories}\")\n",
        "        print(\"  - Azure Custom Vision/VoTT: JSON файли з {asset, regions} в папках annotations/\")\n",
        "        print(\"\\nМожливі причини:\")\n",
        "        print(\"  1. Датасет має інший формат анотацій\")\n",
        "        print(\"  2. Анотації знаходяться в іншій директорії\")\n",
        "        print(\"  3. Датасет не містить файлів анотацій\")\n",
        "        print(\"\\nПеревірте вивід діагностики вище для деталей\")\n",
        "        print(\"=\"*60)\n",
        "        return\n",
        "    \n",
        "    print(f\"Виявлено формат: {format_type}\")\n",
        "    \n",
        "    # Збираємо всі класи\n",
        "    class_names = set()\n",
        "    \n",
        "    if format_type == \"pascal_voc\":\n",
        "        xml_files = format_data\n",
        "        for xml_file in tqdm(xml_files, desc=\"Збір класів\"):\n",
        "            tree = ET.parse(xml_file)\n",
        "            root = tree.getroot()\n",
        "            for obj in root.findall('object'):\n",
        "                class_name = obj.find('name').text\n",
        "                class_names.add(class_name)\n",
        "        \n",
        "        # Створюємо мапінг класів\n",
        "        class_names = sorted(list(class_names))\n",
        "        class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
        "        \n",
        "        # Конвертуємо файли\n",
        "        all_files = []\n",
        "        for xml_file in tqdm(xml_files, desc=\"Конвертація\"):\n",
        "            # Шукаємо відповідне зображення\n",
        "            img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "            img_file = None\n",
        "            for ext in img_extensions:\n",
        "                potential_img = xml_file.parent / (xml_file.stem + ext)\n",
        "                if potential_img.exists():\n",
        "                    img_file = potential_img\n",
        "                    break\n",
        "            \n",
        "            if img_file is None:\n",
        "                continue\n",
        "            \n",
        "            boxes, img_width, img_height = parse_pascal_voc(xml_file)\n",
        "            \n",
        "            # Записуємо YOLO формат\n",
        "            yolo_labels = []\n",
        "            for box in boxes:\n",
        "                class_id = class_mapping[box['class']]\n",
        "                bbox = box['bbox']\n",
        "                yolo_labels.append(f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\")\n",
        "            \n",
        "            all_files.append((img_file, yolo_labels))\n",
        "    \n",
        "    elif format_type == \"coco\":\n",
        "        json_file = format_data\n",
        "        images, categories, annotations_by_image = parse_coco(json_file)\n",
        "        \n",
        "        # Створюємо мапінг класів\n",
        "        class_names = sorted(list(categories.values()))\n",
        "        class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
        "        \n",
        "        # Конвертуємо\n",
        "        yolo_data = convert_coco_to_yolo(images, categories, annotations_by_image, class_mapping)\n",
        "        \n",
        "        # Знаходимо зображення\n",
        "        img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "        all_files = []\n",
        "        for file_name, boxes in tqdm(yolo_data.items(), desc=\"Конвертація\"):\n",
        "            img_file = None\n",
        "            for ext in img_extensions:\n",
        "                potential_img = input_path / file_name\n",
        "                if potential_img.exists():\n",
        "                    img_file = potential_img\n",
        "                    break\n",
        "                # Шукаємо рекурсивно\n",
        "                for found_img in input_path.rglob(file_name):\n",
        "                    img_file = found_img\n",
        "                    break\n",
        "            \n",
        "            if img_file is None or not img_file.exists():\n",
        "                continue\n",
        "            \n",
        "            yolo_labels = []\n",
        "            for box in boxes:\n",
        "                yolo_labels.append(\n",
        "                    f\"{box['class_id']} {box['bbox'][0]:.6f} {box['bbox'][1]:.6f} \"\n",
        "                    f\"{box['bbox'][2]:.6f} {box['bbox'][3]:.6f}\"\n",
        "                )\n",
        "            \n",
        "            all_files.append((img_file, yolo_labels))\n",
        "    \n",
        "    elif format_type == \"azure_custom_vision\":\n",
        "        json_files = format_data\n",
        "        \n",
        "        # Групуємо JSON файли по директоріям (кожна директорія класу має свою папку annotations)\n",
        "        json_by_dir = {}\n",
        "        for json_file in json_files:\n",
        "            parent_dir = json_file.parent.parent  # Директорія класу\n",
        "            if parent_dir not in json_by_dir:\n",
        "                json_by_dir[parent_dir] = []\n",
        "            json_by_dir[parent_dir].append(json_file)\n",
        "        \n",
        "        # Збираємо всі класи (використовуємо множину для зберігання)\n",
        "        classes_set = set(class_names)  # Створюємо копію множини\n",
        "        \n",
        "        for json_file in tqdm(json_files, desc=\"Збір класів\"):\n",
        "            try:\n",
        "                boxes, _, _ = parse_azure_custom_vision(json_file)\n",
        "                for box in boxes:\n",
        "                    if box.get('class'):\n",
        "                        classes_set.add(box['class'])\n",
        "            except Exception as e:\n",
        "                continue\n",
        "        \n",
        "        # Створюємо мапінг класів (поки що без нових класів)\n",
        "        class_names = sorted(list(classes_set))\n",
        "        class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
        "        \n",
        "        # Конвертуємо файли\n",
        "        all_files = []\n",
        "        img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "        \n",
        "        # Обробляємо кожну директорію окремо\n",
        "        for parent_dir, dir_json_files in json_by_dir.items():\n",
        "            # Отримуємо всі зображення в цій директорії\n",
        "            all_images = []\n",
        "            for ext in img_extensions:\n",
        "                all_images.extend(list(parent_dir.glob(f\"*{ext}\")))\n",
        "                all_images.extend(list(parent_dir.glob(f\"*{ext.upper()}\")))\n",
        "            \n",
        "            # Сортуємо для узгодженості\n",
        "            all_images = sorted(all_images, key=lambda x: x.name)\n",
        "            dir_json_files = sorted(dir_json_files, key=lambda x: x.name)\n",
        "            \n",
        "            # Створюємо мапу між JSON та зображеннями\n",
        "            # Якщо кількість збігається, зв'язуємо за порядком\n",
        "            json_to_img = {}\n",
        "            if len(dir_json_files) == len(all_images):\n",
        "                # Точна відповідність - зв'язуємо за порядком\n",
        "                for json_file, img_file in zip(dir_json_files, all_images):\n",
        "                    json_to_img[json_file] = img_file\n",
        "            else:\n",
        "                # Намагаємося знайти відповідність за назвою\n",
        "                for json_file in dir_json_files:\n",
        "                    json_stem = json_file.stem\n",
        "                    # Видаляємо суфікс \"-asset\" якщо є\n",
        "                    if json_stem.endswith('-asset'):\n",
        "                        json_stem = json_stem[:-6]\n",
        "                    \n",
        "                    img_file = None\n",
        "                    # Шукаємо за точним ім'ям\n",
        "                    for ext in img_extensions:\n",
        "                        potential_img = parent_dir / (json_stem + ext)\n",
        "                        if potential_img.exists():\n",
        "                            img_file = potential_img\n",
        "                            break\n",
        "                    \n",
        "                    # Якщо не знайшли, шукаємо за частиною назви\n",
        "                    if img_file is None:\n",
        "                        for img_path in all_images:\n",
        "                            img_stem = img_path.stem\n",
        "                            if json_stem in img_stem or img_stem in json_stem:\n",
        "                                img_file = img_path\n",
        "                                break\n",
        "                    \n",
        "                    if img_file is not None:\n",
        "                        json_to_img[json_file] = img_file\n",
        "        \n",
        "        # Обробляємо всі JSON файли\n",
        "        for json_file in tqdm(json_files, desc=\"Конвертація\"):\n",
        "            try:\n",
        "                # Отримуємо відповідне зображення\n",
        "                img_file = json_to_img.get(json_file)\n",
        "                \n",
        "                if img_file is None or not img_file.exists():\n",
        "                    continue\n",
        "                \n",
        "                # Отримуємо назву директорії класу\n",
        "                parent_dir = json_file.parent.parent\n",
        "                dir_class = parent_dir.name if parent_dir else None\n",
        "                \n",
        "                # Парсимо анотації\n",
        "                boxes, img_width, img_height = parse_azure_custom_vision(json_file, img_path=str(img_file))\n",
        "                \n",
        "                if boxes is None or len(boxes) == 0:\n",
        "                    # Якщо анотацій немає, але зображення є, можливо клас визначається з назви директорії\n",
        "                    # Назва директорії - це назва класу\n",
        "                    if dir_class and dir_class not in ['annotations', 'images', 'labels']:\n",
        "                        classes_set.add(dir_class)\n",
        "                        # Створюємо один bbox на все зображення (якщо потрібно)\n",
        "                        # Але краще пропустити файли без анотацій\n",
        "                    continue\n",
        "                \n",
        "                # Якщо в анотаціях немає класу, але є назва директорії, використовуємо її\n",
        "                for box in boxes:\n",
        "                    if not box.get('class') or box['class'] == '':\n",
        "                        if dir_class and dir_class not in ['annotations', 'images', 'labels']:\n",
        "                            box['class'] = dir_class\n",
        "                            classes_set.add(dir_class)\n",
        "                \n",
        "                # Записуємо YOLO формат\n",
        "                yolo_labels = []\n",
        "                for box in boxes:\n",
        "                    class_name = box.get('class')\n",
        "                    if not class_name:\n",
        "                        continue\n",
        "                    if class_name not in class_mapping:\n",
        "                        # Оновлюємо мапінг, якщо знайшли новий клас\n",
        "                        classes_set.add(class_name)\n",
        "                        class_names = sorted(list(classes_set))\n",
        "                        class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
        "                    class_id = class_mapping[class_name]\n",
        "                    bbox = box['bbox']\n",
        "                    yolo_labels.append(f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\")\n",
        "                \n",
        "                if len(yolo_labels) > 0:\n",
        "                    all_files.append((img_file, yolo_labels))\n",
        "            except Exception as e:\n",
        "                print(f\"Помилка при обробці {json_file}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Оновлюємо class_names з classes_set перед створенням файлів\n",
        "        if format_type == \"azure_custom_vision\":\n",
        "            class_names = sorted(list(classes_set))\n",
        "    \n",
        "    # Розділяємо на train/val/test\n",
        "    random.seed(42)\n",
        "    random.shuffle(all_files)\n",
        "    \n",
        "    n_total = len(all_files)\n",
        "    n_train = int(n_total * train_split)\n",
        "    n_val = int(n_total * val_split)\n",
        "    \n",
        "    splits = {\n",
        "        'train': all_files[:n_train],\n",
        "        'val': all_files[n_train:n_train + n_val],\n",
        "        'test': all_files[n_train + n_val:]\n",
        "    }\n",
        "    \n",
        "    # Копіюємо файли та створюємо labels\n",
        "    for split_name, files in splits.items():\n",
        "        print(f\"\\nОбробка {split_name}: {len(files)} файлів\")\n",
        "        for img_file, yolo_labels in tqdm(files, desc=f\"Копіювання {split_name}\"):\n",
        "            # Копіюємо зображення\n",
        "            dest_img = output_path / split_name / 'images' / img_file.name\n",
        "            shutil.copy2(img_file, dest_img)\n",
        "            \n",
        "            # Створюємо label файл\n",
        "            label_file = output_path / split_name / 'labels' / (img_file.stem + '.txt')\n",
        "            with open(label_file, 'w') as f:\n",
        "                f.write('\\n'.join(yolo_labels))\n",
        "    \n",
        "    # Створюємо файл з назвами класів\n",
        "    classes_file = output_path / 'classes.txt'\n",
        "    with open(classes_file, 'w') as f:\n",
        "        f.write('\\n'.join(class_names))\n",
        "    \n",
        "    # Створюємо data.yaml для YOLO\n",
        "    yaml_content = f\"\"\"# ArTaxOr Dataset Configuration\n",
        "path: {output_path.absolute()}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "# Classes\n",
        "nc: {len(class_names)}\n",
        "names: {class_names}\n",
        "\"\"\"\n",
        "    \n",
        "    yaml_file = output_path / 'data.yaml'\n",
        "    with open(yaml_file, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "    \n",
        "    print(f\"\\nКонвертацію завершено!\")\n",
        "    print(f\"Вихідний датасет: {output_path}\")\n",
        "    print(f\"Кількість класів: {len(class_names)}\")\n",
        "    print(f\"Класи: {', '.join(class_names)}\")\n",
        "    print(f\"Конфігурація: {yaml_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Конвертуємо датасет\n",
        "convert_dataset(\n",
        "    input_path=DATASET_DIR,\n",
        "    output_path=YOLO_DATASET_DIR,\n",
        "    train_split=0.8,\n",
        "    val_split=0.1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Перевірка структури конвертованого датасету\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Перевіряємо структуру датасету\n",
        "data_yaml = os.path.join(YOLO_DATASET_DIR, \"data.yaml\")\n",
        "if os.path.exists(data_yaml):\n",
        "    print(f\"Файл конфігурації створено: {data_yaml}\")\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        print(\"\\nВміст data.yaml:\")\n",
        "        print(f.read())\n",
        "    \n",
        "    # Показуємо статистику\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        images_dir = os.path.join(YOLO_DATASET_DIR, split, 'images')\n",
        "        labels_dir = os.path.join(YOLO_DATASET_DIR, split, 'labels')\n",
        "        if os.path.exists(images_dir):\n",
        "            num_images = len([f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "            num_labels = len([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
        "            print(f\"\\n{split.upper()}: {num_images} зображень, {num_labels} labels\")\n",
        "else:\n",
        "    print(f\"ПОМИЛКА: Файл конфігурації не знайдено: {data_yaml}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Навчання моделі YOLOv8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Параметри навчання\n",
        "MODEL_SIZE = 'n'  # n, s, m, l, x (nano, small, medium, large, xlarge)\n",
        "EPOCHS = 1\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 16\n",
        "DEVICE = 'cuda' if os.environ.get('CUDA_VISIBLE_DEVICES') else 'cpu'\n",
        "PROJECT_NAME = 'artaxor_training'\n",
        "\n",
        "print(f\"Параметри навчання:\")\n",
        "print(f\"   - Модель: YOLOv8{MODEL_SIZE}\")\n",
        "print(f\"   - Епохи: {EPOCHS}\")\n",
        "print(f\"   - Розмір зображення: {IMG_SIZE}\")\n",
        "print(f\"   - Батч: {BATCH_SIZE}\")\n",
        "print(f\"   - Пристрій: {DEVICE}\")\n",
        "print(f\"   - Датасет: {data_yaml}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Завантажуємо модель\n",
        "model_name = f'yolov8{MODEL_SIZE}.pt'\n",
        "print(f\"Завантаження попередньо навченої моделі: {model_name}\")\n",
        "model = YOLO(model_name)\n",
        "\n",
        "print(\"Модель завантажено успішно!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Початок навчання\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ПОЧАТОК НАВЧАННЯ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMG_SIZE,\n",
        "    batch=BATCH_SIZE,\n",
        "    device=DEVICE,\n",
        "    project=OUTPUT_DIR,\n",
        "    name=PROJECT_NAME,\n",
        "    save=True,\n",
        "    save_period=10,  # Зберігати чекпоінт кожні 10 епох\n",
        "    val=True,  # Валідація під час навчання\n",
        "    plots=True,  # Генерувати графіки\n",
        "    verbose=True,  # Показувати детальний прогрес навчання\n",
        "    seed=42,  # Для відтворюваності\n",
        "    deterministic=True,\n",
        "    amp=True,  # Automatic Mixed Precision (швидше навчання)\n",
        "    cos_lr=True,  # Cosine learning rate schedule\n",
        "    close_mosaic=10,  # Вимкнути mosaic за 10 епох до кінця\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "hours = int(training_time // 3600)\n",
        "minutes = int((training_time % 3600) // 60)\n",
        "seconds = int(training_time % 60)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"НАВЧАННЯ ЗАВЕРШЕНО!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Час навчання: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Результати навчання\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Шляхи до результатів\n",
        "# Спочатку намагаємося отримати шлях з об'єкта results\n",
        "try:\n",
        "    if 'results' in globals() and hasattr(results, 'save_dir'):\n",
        "        results_dir = str(results.save_dir)\n",
        "    elif 'results' in globals() and hasattr(results, 'save_path'):\n",
        "        # Іноді YOLO зберігає шлях в save_path\n",
        "        results_dir = os.path.dirname(str(results.save_path)) if results.save_path else os.path.join(OUTPUT_DIR, PROJECT_NAME)\n",
        "    else:\n",
        "        results_dir = os.path.join(OUTPUT_DIR, PROJECT_NAME)\n",
        "except:\n",
        "    results_dir = os.path.join(OUTPUT_DIR, PROJECT_NAME)\n",
        "\n",
        "# Шукаємо модель в різних можливих місцях\n",
        "best_model = None\n",
        "last_model = None\n",
        "\n",
        "# Можливі шляхи до моделей\n",
        "possible_best_paths = [\n",
        "    os.path.join(results_dir, 'weights', 'best.pt'),\n",
        "    os.path.join(results_dir, 'best.pt'),\n",
        "    os.path.join(OUTPUT_DIR, PROJECT_NAME, 'weights', 'best.pt'),\n",
        "    os.path.join(OUTPUT_DIR, PROJECT_NAME, 'best.pt'),\n",
        "]\n",
        "\n",
        "possible_last_paths = [\n",
        "    os.path.join(results_dir, 'weights', 'last.pt'),\n",
        "    os.path.join(results_dir, 'last.pt'),\n",
        "    os.path.join(OUTPUT_DIR, PROJECT_NAME, 'weights', 'last.pt'),\n",
        "    os.path.join(OUTPUT_DIR, PROJECT_NAME, 'last.pt'),\n",
        "]\n",
        "\n",
        "# Також перевіряємо, чи є weights директорія і шукаємо там\n",
        "weights_dir = os.path.join(results_dir, 'weights')\n",
        "if os.path.exists(weights_dir):\n",
        "    # Шукаємо всі .pt файли в weights\n",
        "    for file in os.listdir(weights_dir):\n",
        "        if file.endswith('.pt'):\n",
        "            file_path = os.path.join(weights_dir, file)\n",
        "            if 'best' in file.lower() and best_model is None:\n",
        "                best_model = file_path\n",
        "            elif 'last' in file.lower() and last_model is None:\n",
        "                last_model = file_path\n",
        "\n",
        "# Якщо не знайшли через список файлів, перевіряємо стандартні шляхи\n",
        "if best_model is None:\n",
        "    for path in possible_best_paths:\n",
        "        if os.path.exists(path):\n",
        "            best_model = path\n",
        "            break\n",
        "\n",
        "if last_model is None:\n",
        "    for path in possible_last_paths:\n",
        "        if os.path.exists(path):\n",
        "            last_model = path\n",
        "            break\n",
        "\n",
        "print(f\"Результати збережено в: {results_dir}\")\n",
        "if best_model:\n",
        "    print(f\"Найкраща модель: {best_model}\")\n",
        "else:\n",
        "    print(\"Найкраща модель не знайдена\")\n",
        "    # Показуємо структуру директорії для діагностики\n",
        "    if os.path.exists(results_dir):\n",
        "        print(f\"\\nСтруктура директорії {results_dir}:\")\n",
        "        for root, dirs, files in os.walk(results_dir):\n",
        "            level = root.replace(results_dir, '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files[:5]:\n",
        "                print(f\"{subindent}{file}\")\n",
        "            if len(files) > 5:\n",
        "                print(f\"{subindent}... та ще {len(files) - 5} файлів\")\n",
        "\n",
        "if last_model:\n",
        "    print(f\"Остання модель: {last_model}\")\n",
        "else:\n",
        "    print(\"Остання модель не знайдена\")\n",
        "\n",
        "# Виводимо метрики\n",
        "if hasattr(results, 'results_dict'):\n",
        "    print(\"\\nМетрики навчання:\")\n",
        "    for key, value in results.results_dict.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "# Показуємо графіки результатів\n",
        "results_png = os.path.join(results_dir, 'results.png')\n",
        "if os.path.exists(results_png):\n",
        "    print(f\"\\nГрафіки результатів: {results_png}\")\n",
        "    from IPython.display import Image, display\n",
        "    display(Image(results_png))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Валідація моделі (опціонально)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Валідація найкращої моделі\n",
        "if best_model and os.path.exists(best_model):\n",
        "    print(f\"Валідація моделі: {best_model}\")\n",
        "    validation_model = YOLO(best_model)\n",
        "    \n",
        "    val_results = validation_model.val(\n",
        "        data=data_yaml,\n",
        "        imgsz=IMG_SIZE,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"РЕЗУЛЬТАТИ ВАЛІДАЦІЇ:\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"   mAP50: {val_results.box.map50:.4f}\")\n",
        "    print(f\"   mAP50-95: {val_results.box.map:.4f}\")\n",
        "    if hasattr(val_results.box, 'mp'):\n",
        "        print(f\"   Precision: {val_results.box.mp:.4f}\")\n",
        "    if hasattr(val_results.box, 'mr'):\n",
        "        print(f\"   Recall: {val_results.box.mr:.4f}\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    if best_model:\n",
        "        print(f\"ПОМИЛКА: Модель не знайдено: {best_model}\")\n",
        "    else:\n",
        "        print(\"ПОМИЛКА: Модель не знайдено. Перевірте, чи навчання завершилося успішно.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Тестування на прикладі зображення (опціонально)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Знаходимо тестове зображення\n",
        "test_images_dir = os.path.join(YOLO_DATASET_DIR, 'test', 'images')\n",
        "if os.path.exists(test_images_dir):\n",
        "    test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    if test_images:\n",
        "        test_image_path = os.path.join(test_images_dir, test_images[0])\n",
        "        print(f\"Тестування на зображенні: {test_image_path}\")\n",
        "        \n",
        "        if best_model and os.path.exists(best_model):\n",
        "            test_model = YOLO(best_model)\n",
        "            \n",
        "            # Передбачення\n",
        "            predictions = test_model.predict(\n",
        "                source=test_image_path,\n",
        "                conf=0.25,\n",
        "                save=True,\n",
        "                save_dir=os.path.join(OUTPUT_DIR, 'predictions'),\n",
        "                show_labels=True,\n",
        "                show_boxes=True\n",
        "            )\n",
        "            \n",
        "            # Показуємо результат\n",
        "            for result in predictions:\n",
        "                print(f\"\\nЗнайдено об'єктів: {len(result.boxes)}\")\n",
        "                if len(result.boxes) > 0:\n",
        "                    print(\"\\nДеталі детекцій:\")\n",
        "                    for i, box in enumerate(result.boxes):\n",
        "                        cls = int(box.cls[0])\n",
        "                        conf = float(box.conf[0])\n",
        "                        class_name = test_model.names[cls]\n",
        "                        print(f\"   {i+1}. {class_name}: {conf:.2%}\")\n",
        "                    \n",
        "                    # Показуємо зображення з детекціями\n",
        "                    from IPython.display import Image, display\n",
        "                    result_path = os.path.join(OUTPUT_DIR, 'predictions', test_images[0])\n",
        "                    if os.path.exists(result_path):\n",
        "                        display(Image(result_path))\n",
        "        else:\n",
        "            print(f\"ПОМИЛКА: Модель не знайдено: {best_model}\")\n",
        "    else:\n",
        "        print(f\"ПОМИЛКА: Тестові зображення не знайдено в {test_images_dir}\")\n",
        "else:\n",
        "    print(f\"ПОМИЛКА: Тестова директорія не знайдено: {test_images_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Примітки\n",
        "\n",
        "- Для кращих результатів рекомендується використовувати GPU\n",
        "- Розмір батчу залежить від доступної пам'яті GPU\n",
        "- Моделі більшого розміру (l, x) потребують більше пам'яті та часу навчання\n",
        "- Рекомендується почати з моделі `n` (nano) для швидкого тестування\n",
        "- Змініть параметри `MODEL_SIZE`, `EPOCHS`, `BATCH_SIZE` у комірці 7 для налаштування навчання\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
