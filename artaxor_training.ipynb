{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Донавчання детектора об'єктів на датасеті ArTaxOr\n",
    "\n",
    "Цей notebook містить повний пайплайн для донавчання моделі YOLOv8 на датасеті [ArTaxOr (Arthropod Taxonomy Orders Object Detection Dataset)](https://www.kaggle.com/datasets/mistag/arthropod-taxonomy-orders-object-detection-dataset) з Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Встановлення залежностей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics>=8.0.0 -q\n",
    "%pip install opencv-python>=4.8.0 -q\n",
    "%pip install pillow>=10.0.0 -q\n",
    "%pip install pyyaml>=6.0 -q\n",
    "%pip install tqdm>=4.65.0 -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Імпорт бібліотек\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Завантаження датасету з Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Налаштування шляхів\n",
    "INPUT_DIR = \"/kaggle/input/arthropod-taxonomy-orders-object-detection-dataset\"\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "YOLO_DATASET_DIR = os.path.join(OUTPUT_DIR, \"yolo_dataset\")\n",
    "\n",
    "print(f\"Вхідна директорія: {INPUT_DIR}\")\n",
    "print(f\"Робоча директорія: {OUTPUT_DIR}\")\n",
    "\n",
    "# Автоматичний пошук датасету\n",
    "DATASET_DIR = None\n",
    "\n",
    "# Перевіряємо різні можливі шляхи\n",
    "possible_paths = [\n",
    "    os.path.join(INPUT_DIR, \"ArTaxOr\"),\n",
    "    INPUT_DIR,  # Датасет може бути безпосередньо в INPUT_DIR\n",
    "]\n",
    "\n",
    "# Також шукаємо рекурсивно в INPUT_DIR\n",
    "if os.path.exists(INPUT_DIR):\n",
    "    for root, dirs, files in os.walk(INPUT_DIR):\n",
    "        # Шукаємо директорії, які містять XML або JSON файли (анотації)\n",
    "        xml_files = [f for f in files if f.endswith('.xml')]\n",
    "        json_files = [f for f in files if f.endswith('.json')]\n",
    "        if xml_files or json_files:\n",
    "            DATASET_DIR = root\n",
    "            break\n",
    "        # Або шукаємо директорію з назвою ArTaxOr\n",
    "        if 'ArTaxOr' in dirs:\n",
    "            DATASET_DIR = os.path.join(root, 'ArTaxOr')\n",
    "            break\n",
    "\n",
    "# Якщо не знайшли, перевіряємо стандартні шляхи\n",
    "if DATASET_DIR is None:\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            # Перевіряємо, чи є там XML або JSON файли\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                xml_files = [f for f in files if f.endswith('.xml')]\n",
    "                json_files = [f for f in files if f.endswith('.json')]\n",
    "                if xml_files or json_files:\n",
    "                    DATASET_DIR = path\n",
    "                    break\n",
    "            if DATASET_DIR:\n",
    "                break\n",
    "\n",
    "if DATASET_DIR and os.path.exists(DATASET_DIR):\n",
    "    print(f\"\\nДатасет знайдено в: {DATASET_DIR}\")\n",
    "    # Показуємо структуру датасету (перші 3 рівні)\n",
    "    print(\"\\nСтруктура датасету:\")\n",
    "    for root, dirs, files in os.walk(DATASET_DIR):\n",
    "        level = root.replace(DATASET_DIR, '').count(os.sep)\n",
    "        if level > 2:  # Обмежуємо глибину для читабельності\n",
    "            continue\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        # Показуємо файли анотацій\n",
    "        annotation_files = [f for f in files if f.endswith(('.xml', '.json'))]\n",
    "        if annotation_files:\n",
    "            for file in annotation_files[:3]:\n",
    "                print(f\"{subindent}{file}\")\n",
    "            if len(annotation_files) > 3:\n",
    "                print(f\"{subindent}... та ще {len(annotation_files) - 3} файлів анотацій\")\n",
    "        # Показуємо зображення\n",
    "        image_files = [f for f in files if f.endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "        if image_files and not annotation_files:\n",
    "            for file in image_files[:3]:\n",
    "                print(f\"{subindent}{file}\")\n",
    "            if len(image_files) > 3:\n",
    "                print(f\"{subindent}... та ще {len(image_files) - 3} зображень\")\n",
    "else:\n",
    "    print(f\"\\nПОПЕРЕДЖЕННЯ: Датасет не знайдено\")\n",
    "    print(f\"Перевірено шляхи:\")\n",
    "    for path in possible_paths:\n",
    "        exists = \"існує\" if os.path.exists(path) else \"не існує\"\n",
    "        print(f\"  - {path} ({exists})\")\n",
    "    print(\"\\nПереконайтеся, що:\")\n",
    "    print(\"1. Датасет додано до notebook через Add Data -> Search Datasets\")\n",
    "    print(\"2. Назва датасету: arthropod-taxonomy-orders-object-detection-dataset\")\n",
    "    print(\"3. Автор датасету: mistag\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Функції для конвертації датасету у формат YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pascal_voc(xml_path):\n",
    "    \"\"\"\n",
    "    Парсить XML файл у форматі Pascal VOC\n",
    "    Повертає список bbox у форматі [class_id, x_center, y_center, width, height] (нормалізовані)\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Отримуємо розміри зображення\n",
    "    size = root.find('size')\n",
    "    img_width = int(size.find('width').text)\n",
    "    img_height = int(size.find('height').text)\n",
    "    \n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        # Отримуємо клас (може бути name або class)\n",
    "        class_name = obj.find('name').text\n",
    "        \n",
    "        # Отримуємо bbox\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text)\n",
    "        ymin = float(bbox.find('ymin').text)\n",
    "        xmax = float(bbox.find('xmax').text)\n",
    "        ymax = float(bbox.find('ymax').text)\n",
    "        \n",
    "        # Конвертуємо в YOLO формат (нормалізовані координати центру та розміри)\n",
    "        x_center = ((xmin + xmax) / 2) / img_width\n",
    "        y_center = ((ymin + ymax) / 2) / img_height\n",
    "        width = (xmax - xmin) / img_width\n",
    "        height = (ymax - ymin) / img_height\n",
    "        \n",
    "        boxes.append({\n",
    "            'class': class_name,\n",
    "            'bbox': [x_center, y_center, width, height]\n",
    "        })\n",
    "    \n",
    "    return boxes, img_width, img_height\n",
    "\n",
    "def parse_coco(json_path):\n",
    "    \"\"\"\n",
    "    Парсить JSON файл у форматі COCO\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Створюємо мапи для швидкого пошуку\n",
    "    images = {img['id']: img for img in data['images']}\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    # Групуємо анотації по зображенням\n",
    "    annotations_by_image = {}\n",
    "    for ann in data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in annotations_by_image:\n",
    "            annotations_by_image[image_id] = []\n",
    "        annotations_by_image[image_id].append(ann)\n",
    "    \n",
    "    return images, categories, annotations_by_image\n",
    "\n",
    "def convert_coco_to_yolo(images, categories, annotations_by_image, class_mapping):\n",
    "    \"\"\"\n",
    "    Конвертує анотації COCO у формат YOLO\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for image_id, image_info in images.items():\n",
    "        img_width = image_info['width']\n",
    "        img_height = image_info['height']\n",
    "        file_name = image_info['file_name']\n",
    "        \n",
    "        boxes = []\n",
    "        if image_id in annotations_by_image:\n",
    "            for ann in annotations_by_image[image_id]:\n",
    "                category_id = ann['category_id']\n",
    "                class_name = categories[category_id]\n",
    "                \n",
    "                if class_name not in class_mapping:\n",
    "                    continue\n",
    "                \n",
    "                class_id = class_mapping[class_name]\n",
    "                \n",
    "                # COCO bbox формат: [x_min, y_min, width, height]\n",
    "                x_min, y_min, width, height = ann['bbox']\n",
    "                \n",
    "                # Конвертуємо в YOLO формат\n",
    "                x_center = (x_min + width / 2) / img_width\n",
    "                y_center = (y_min + height / 2) / img_height\n",
    "                norm_width = width / img_width\n",
    "                norm_height = height / img_height\n",
    "                \n",
    "                boxes.append({\n",
    "                    'class_id': class_id,\n",
    "                    'bbox': [x_center, y_center, norm_width, norm_height]\n",
    "                })\n",
    "        \n",
    "        result[file_name] = boxes\n",
    "    \n",
    "    return result\n",
    "\n",
    "def detect_format(dataset_path):\n",
    "    \"\"\"\n",
    "    Визначає формат анотацій датасету\n",
    "    \"\"\"\n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    # Перевірка на Pascal VOC (XML файли)\n",
    "    xml_files = list(dataset_path.rglob(\"*.xml\"))\n",
    "    if xml_files:\n",
    "        return \"pascal_voc\", xml_files\n",
    "    \n",
    "    # Перевірка на COCO (JSON файли)\n",
    "    json_files = list(dataset_path.rglob(\"*.json\"))\n",
    "    if json_files:\n",
    "        # Шукаємо файл з annotations\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    if 'images' in data and 'annotations' in data and 'categories' in data:\n",
    "                        return \"coco\", json_file\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset(input_path, output_path, train_split=0.8, val_split=0.1):\n",
    "    \"\"\"\n",
    "    Конвертує датасет у формат YOLO\n",
    "    \n",
    "    Args:\n",
    "        input_path: Шлях до вхідного датасету\n",
    "        output_path: Шлях для вихідного датасету YOLO\n",
    "        train_split: Частка даних для навчання\n",
    "        val_split: Частка даних для валідації\n",
    "    \"\"\"\n",
    "    input_path = Path(input_path)\n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    # Створюємо структуру директорій YOLO\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (output_path / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (output_path / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Визначаємо формат датасету\n",
    "    format_type, format_data = detect_format(input_path)\n",
    "    \n",
    "    if format_type is None:\n",
    "        print(\"Помилка: не вдалося визначити формат анотацій\")\n",
    "        print(\"Підтримувані формати: Pascal VOC (XML), COCO (JSON)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Виявлено формат: {format_type}\")\n",
    "    \n",
    "    # Збираємо всі класи\n",
    "    class_names = set()\n",
    "    \n",
    "    if format_type == \"pascal_voc\":\n",
    "        xml_files = format_data\n",
    "        for xml_file in tqdm(xml_files, desc=\"Збір класів\"):\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                class_name = obj.find('name').text\n",
    "                class_names.add(class_name)\n",
    "        \n",
    "        # Створюємо мапінг класів\n",
    "        class_names = sorted(list(class_names))\n",
    "        class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
    "        \n",
    "        # Конвертуємо файли\n",
    "        all_files = []\n",
    "        for xml_file in tqdm(xml_files, desc=\"Конвертація\"):\n",
    "            # Шукаємо відповідне зображення\n",
    "            img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "            img_file = None\n",
    "            for ext in img_extensions:\n",
    "                potential_img = xml_file.parent / (xml_file.stem + ext)\n",
    "                if potential_img.exists():\n",
    "                    img_file = potential_img\n",
    "                    break\n",
    "            \n",
    "            if img_file is None:\n",
    "                continue\n",
    "            \n",
    "            boxes, img_width, img_height = parse_pascal_voc(xml_file)\n",
    "            \n",
    "            # Записуємо YOLO формат\n",
    "            yolo_labels = []\n",
    "            for box in boxes:\n",
    "                class_id = class_mapping[box['class']]\n",
    "                bbox = box['bbox']\n",
    "                yolo_labels.append(f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\")\n",
    "            \n",
    "            all_files.append((img_file, yolo_labels))\n",
    "    \n",
    "    elif format_type == \"coco\":\n",
    "        json_file = format_data\n",
    "        images, categories, annotations_by_image = parse_coco(json_file)\n",
    "        \n",
    "        # Створюємо мапінг класів\n",
    "        class_names = sorted(list(categories.values()))\n",
    "        class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
    "        \n",
    "        # Конвертуємо\n",
    "        yolo_data = convert_coco_to_yolo(images, categories, annotations_by_image, class_mapping)\n",
    "        \n",
    "        # Знаходимо зображення\n",
    "        img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "        all_files = []\n",
    "        for file_name, boxes in tqdm(yolo_data.items(), desc=\"Конвертація\"):\n",
    "            img_file = None\n",
    "            for ext in img_extensions:\n",
    "                potential_img = input_path / file_name\n",
    "                if potential_img.exists():\n",
    "                    img_file = potential_img\n",
    "                    break\n",
    "                # Шукаємо рекурсивно\n",
    "                for found_img in input_path.rglob(file_name):\n",
    "                    img_file = found_img\n",
    "                    break\n",
    "            \n",
    "            if img_file is None or not img_file.exists():\n",
    "                continue\n",
    "            \n",
    "            yolo_labels = []\n",
    "            for box in boxes:\n",
    "                yolo_labels.append(\n",
    "                    f\"{box['class_id']} {box['bbox'][0]:.6f} {box['bbox'][1]:.6f} \"\n",
    "                    f\"{box['bbox'][2]:.6f} {box['bbox'][3]:.6f}\"\n",
    "                )\n",
    "            \n",
    "            all_files.append((img_file, yolo_labels))\n",
    "    \n",
    "    # Розділяємо на train/val/test\n",
    "    random.seed(42)\n",
    "    random.shuffle(all_files)\n",
    "    \n",
    "    n_total = len(all_files)\n",
    "    n_train = int(n_total * train_split)\n",
    "    n_val = int(n_total * val_split)\n",
    "    \n",
    "    splits = {\n",
    "        'train': all_files[:n_train],\n",
    "        'val': all_files[n_train:n_train + n_val],\n",
    "        'test': all_files[n_train + n_val:]\n",
    "    }\n",
    "    \n",
    "    # Копіюємо файли та створюємо labels\n",
    "    for split_name, files in splits.items():\n",
    "        print(f\"\\nОбробка {split_name}: {len(files)} файлів\")\n",
    "        for img_file, yolo_labels in tqdm(files, desc=f\"Копіювання {split_name}\"):\n",
    "            # Копіюємо зображення\n",
    "            dest_img = output_path / split_name / 'images' / img_file.name\n",
    "            shutil.copy2(img_file, dest_img)\n",
    "            \n",
    "            # Створюємо label файл\n",
    "            label_file = output_path / split_name / 'labels' / (img_file.stem + '.txt')\n",
    "            with open(label_file, 'w') as f:\n",
    "                f.write('\\n'.join(yolo_labels))\n",
    "    \n",
    "    # Створюємо файл з назвами класів\n",
    "    classes_file = output_path / 'classes.txt'\n",
    "    with open(classes_file, 'w') as f:\n",
    "        f.write('\\n'.join(class_names))\n",
    "    \n",
    "    # Створюємо data.yaml для YOLO\n",
    "    yaml_content = f\"\"\"# ArTaxOr Dataset Configuration\n",
    "path: {output_path.absolute()}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "# Classes\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "    \n",
    "    yaml_file = output_path / 'data.yaml'\n",
    "    with open(yaml_file, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"\\nКонвертацію завершено!\")\n",
    "    print(f\"Вихідний датасет: {output_path}\")\n",
    "    print(f\"Кількість класів: {len(class_names)}\")\n",
    "    print(f\"Класи: {', '.join(class_names)}\")\n",
    "    print(f\"Конфігурація: {yaml_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертуємо датасет\n",
    "convert_dataset(\n",
    "    input_path=DATASET_DIR,\n",
    "    output_path=YOLO_DATASET_DIR,\n",
    "    train_split=0.8,\n",
    "    val_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Перевірка структури конвертованого датасету\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевіряємо структуру датасету\n",
    "data_yaml = os.path.join(YOLO_DATASET_DIR, \"data.yaml\")\n",
    "if os.path.exists(data_yaml):\n",
    "    print(f\"Файл конфігурації створено: {data_yaml}\")\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        print(\"\\nВміст data.yaml:\")\n",
    "        print(f.read())\n",
    "    \n",
    "    # Показуємо статистику\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        images_dir = os.path.join(YOLO_DATASET_DIR, split, 'images')\n",
    "        labels_dir = os.path.join(YOLO_DATASET_DIR, split, 'labels')\n",
    "        if os.path.exists(images_dir):\n",
    "            num_images = len([f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            num_labels = len([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "            print(f\"\\n{split.upper()}: {num_images} зображень, {num_labels} labels\")\n",
    "else:\n",
    "    print(f\"ПОМИЛКА: Файл конфігурації не знайдено: {data_yaml}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Навчання моделі YOLOv8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметри навчання\n",
    "MODEL_SIZE = 'n'  # n, s, m, l, x (nano, small, medium, large, xlarge)\n",
    "EPOCHS = 100\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 'cuda' if os.environ.get('CUDA_VISIBLE_DEVICES') else 'cpu'\n",
    "PROJECT_NAME = 'artaxor_training'\n",
    "\n",
    "print(f\"Параметри навчання:\")\n",
    "print(f\"   - Модель: YOLOv8{MODEL_SIZE}\")\n",
    "print(f\"   - Епохи: {EPOCHS}\")\n",
    "print(f\"   - Розмір зображення: {IMG_SIZE}\")\n",
    "print(f\"   - Батч: {BATCH_SIZE}\")\n",
    "print(f\"   - Пристрій: {DEVICE}\")\n",
    "print(f\"   - Датасет: {data_yaml}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантажуємо модель\n",
    "model_name = f'yolov8{MODEL_SIZE}.pt'\n",
    "print(f\"Завантаження попередньо навченої моделі: {model_name}\")\n",
    "model = YOLO(model_name)\n",
    "\n",
    "print(\"Модель завантажено успішно!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Початок навчання\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ПОЧАТОК НАВЧАННЯ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = model.train(\n",
    "    data=data_yaml,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    project=OUTPUT_DIR,\n",
    "    name=PROJECT_NAME,\n",
    "    save=True,\n",
    "    save_period=10,  # Зберігати чекпоінт кожні 10 епох\n",
    "    val=True,  # Валідація під час навчання\n",
    "    plots=True,  # Генерувати графіки\n",
    "    verbose=True,  # Показувати детальний прогрес навчання\n",
    "    seed=42,  # Для відтворюваності\n",
    "    deterministic=True,\n",
    "    amp=True,  # Automatic Mixed Precision (швидше навчання)\n",
    "    cos_lr=True,  # Cosine learning rate schedule\n",
    "    close_mosaic=10,  # Вимкнути mosaic за 10 епох до кінця\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "hours = int(training_time // 3600)\n",
    "minutes = int((training_time % 3600) // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"НАВЧАННЯ ЗАВЕРШЕНО!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Час навчання: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Результати навчання\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шляхи до результатів\n",
    "results_dir = os.path.join(OUTPUT_DIR, PROJECT_NAME)\n",
    "best_model = os.path.join(results_dir, 'weights', 'best.pt')\n",
    "last_model = os.path.join(results_dir, 'weights', 'last.pt')\n",
    "\n",
    "print(f\"Результати збережено в: {results_dir}\")\n",
    "print(f\"Найкраща модель: {best_model}\")\n",
    "print(f\"Остання модель: {last_model}\")\n",
    "\n",
    "# Виводимо метрики\n",
    "if hasattr(results, 'results_dict'):\n",
    "    print(\"\\nМетрики навчання:\")\n",
    "    for key, value in results.results_dict.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "# Показуємо графіки результатів\n",
    "results_png = os.path.join(results_dir, 'results.png')\n",
    "if os.path.exists(results_png):\n",
    "    print(f\"\\nГрафіки результатів: {results_png}\")\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(results_png))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Валідація моделі (опціонально)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валідація найкращої моделі\n",
    "if os.path.exists(best_model):\n",
    "    print(f\"Валідація моделі: {best_model}\")\n",
    "    validation_model = YOLO(best_model)\n",
    "    \n",
    "    val_results = validation_model.val(\n",
    "        data=data_yaml,\n",
    "        imgsz=IMG_SIZE,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"РЕЗУЛЬТАТИ ВАЛІДАЦІЇ:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"   mAP50: {val_results.box.map50:.4f}\")\n",
    "    print(f\"   mAP50-95: {val_results.box.map:.4f}\")\n",
    "    if hasattr(val_results.box, 'mp'):\n",
    "        print(f\"   Precision: {val_results.box.mp:.4f}\")\n",
    "    if hasattr(val_results.box, 'mr'):\n",
    "        print(f\"   Recall: {val_results.box.mr:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(f\"ПОМИЛКА: Модель не знайдено: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Тестування на прикладі зображення (опціонально)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Знаходимо тестове зображення\n",
    "test_images_dir = os.path.join(YOLO_DATASET_DIR, 'test', 'images')\n",
    "if os.path.exists(test_images_dir):\n",
    "    test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    if test_images:\n",
    "        test_image_path = os.path.join(test_images_dir, test_images[0])\n",
    "        print(f\"Тестування на зображенні: {test_image_path}\")\n",
    "        \n",
    "        if os.path.exists(best_model):\n",
    "            test_model = YOLO(best_model)\n",
    "            \n",
    "            # Передбачення\n",
    "            predictions = test_model.predict(\n",
    "                source=test_image_path,\n",
    "                conf=0.25,\n",
    "                save=True,\n",
    "                save_dir=os.path.join(OUTPUT_DIR, 'predictions'),\n",
    "                show_labels=True,\n",
    "                show_boxes=True\n",
    "            )\n",
    "            \n",
    "            # Показуємо результат\n",
    "            for result in predictions:\n",
    "                print(f\"\\nЗнайдено об'єктів: {len(result.boxes)}\")\n",
    "                if len(result.boxes) > 0:\n",
    "                    print(\"\\nДеталі детекцій:\")\n",
    "                    for i, box in enumerate(result.boxes):\n",
    "                        cls = int(box.cls[0])\n",
    "                        conf = float(box.conf[0])\n",
    "                        class_name = test_model.names[cls]\n",
    "                        print(f\"   {i+1}. {class_name}: {conf:.2%}\")\n",
    "                    \n",
    "                    # Показуємо зображення з детекціями\n",
    "                    from IPython.display import Image, display\n",
    "                    result_path = os.path.join(OUTPUT_DIR, 'predictions', test_images[0])\n",
    "                    if os.path.exists(result_path):\n",
    "                        display(Image(result_path))\n",
    "        else:\n",
    "            print(f\"ПОМИЛКА: Модель не знайдено: {best_model}\")\n",
    "    else:\n",
    "        print(f\"ПОМИЛКА: Тестові зображення не знайдено в {test_images_dir}\")\n",
    "else:\n",
    "    print(f\"ПОМИЛКА: Тестова директорія не знайдено: {test_images_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примітки\n",
    "\n",
    "- Для кращих результатів рекомендується використовувати GPU\n",
    "- Розмір батчу залежить від доступної пам'яті GPU\n",
    "- Моделі більшого розміру (l, x) потребують більше пам'яті та часу навчання\n",
    "- Рекомендується почати з моделі `n` (nano) для швидкого тестування\n",
    "- Змініть параметри `MODEL_SIZE`, `EPOCHS`, `BATCH_SIZE` у комірці 7 для налаштування навчання\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
